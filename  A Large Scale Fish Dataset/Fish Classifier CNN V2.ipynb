{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### ***CNN FISH CLASSIFIER V_2***\n* The dataset used is [A Large Scale Fish Dataset](https://www.kaggle.com/datasets/crowww/a-large-scale-fish-dataset),uploaded by OÄŸuzhan Ulucan on Kaggle\n\n","metadata":{}},{"cell_type":"markdown","source":"### IMPORTS","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-07-15T07:52:53.904242Z","iopub.execute_input":"2022-07-15T07:52:53.904673Z","iopub.status.idle":"2022-07-15T07:53:02.331598Z","shell.execute_reply.started":"2022-07-15T07:52:53.904585Z","shell.execute_reply":"2022-07-15T07:53:02.330759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preventing unnecessary warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# TensorFlow and tf.keras\nimport tensorflow as tf\n\nfrom pathlib import Path\n\n#import useful module for keras library\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# get modules from sklearn library\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import classification_report \n\n#import libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:53:26.285229Z","iopub.execute_input":"2022-07-15T07:53:26.285540Z","iopub.status.idle":"2022-07-15T07:53:32.202827Z","shell.execute_reply.started":"2022-07-15T07:53:26.285514Z","shell.execute_reply":"2022-07-15T07:53:32.201970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LOADING DATASET","metadata":{}},{"cell_type":"code","source":"file = Path(\"../input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset\") #dataset location path\nFile_Path = list(file.glob(r\"**/*.png\"))\nLabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],File_Path))\n\nFile_Path = pd.Series(File_Path).astype(str)\nLabels = pd.Series(Labels)\ndf = pd.concat([File_Path,Labels],axis=1)\ndf.columns = ['image', 'label']\n# Drop all the images that ends with (GT)\n\ndf = df[df[\"label\"].apply(lambda x: x[-2:] != \"GT\")].reset_index(drop=True)\n\ndf.head() #get first 5 rows of the dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:53:46.525362Z","iopub.execute_input":"2022-07-15T07:53:46.525682Z","iopub.status.idle":"2022-07-15T07:53:46.972915Z","shell.execute_reply.started":"2022-07-15T07:53:46.525652Z","shell.execute_reply":"2022-07-15T07:53:46.972108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DATA VISUALIZATION","metadata":{}},{"cell_type":"code","source":"# Display 12 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=4, figsize=(14, 8),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax ,in enumerate(axes.flat):\n    ax.imshow(plt.imread(df.image[i]))\n    ax.set_title(df.label[i])\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:53:49.686392Z","iopub.execute_input":"2022-07-15T07:53:49.686708Z","iopub.status.idle":"2022-07-15T07:53:51.604325Z","shell.execute_reply.started":"2022-07-15T07:53:49.686678Z","shell.execute_reply":"2022-07-15T07:53:51.603491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TRAIN TEST SPLIT","metadata":{}},{"cell_type":"code","source":"# split remaining data into train and test sets\nTrain_set, test_set = train_test_split(df, test_size = 0.3, random_state = 42)\n\n#splitting the train set into train and evaluation set\n\ntrain_set, val_set = train_test_split(Train_set, test_size= 0.2, random_state = 42)\n\nprint(train_set.shape)\nprint(test_set.shape)\nprint(val_set.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:53:58.277699Z","iopub.execute_input":"2022-07-15T07:53:58.278039Z","iopub.status.idle":"2022-07-15T07:53:58.290526Z","shell.execute_reply.started":"2022-07-15T07:53:58.278008Z","shell.execute_reply":"2022-07-15T07:53:58.289639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_gen = ImageDataGenerator(preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input, rescale=1/255)\n\n# img_gen cannot take in an array, so ensure the data that is been passed is a dataframe\ntrain = img_gen.flow_from_dataframe(dataframe = train_set,\n    x_col = 'image', #name of the column containing the image in the train set\n    y_col ='label', #name of column containing the target in the train set\n    target_size = (224, 224),\n    color_mode = 'rgb',\n    class_mode = 'categorical',#the class mode here and that for the model_loss(when using sequential model)\n                                    #should be the same\n    batch_size = 32,\n    shuffle = False #not to shuffle the given data\n)\n\ntest = img_gen.flow_from_dataframe(dataframe = test_set,\n    x_col = 'image', #name of the column containing the image in the test set\n    y_col ='label', #name of column containing the target in the test set\n    target_size =(224, 224),\n    color_mode ='rgb',\n    class_mode ='categorical',\n    batch_size = 32,\n    shuffle = False # not to shuffle the given data\n)\n\n\nval = img_gen.flow_from_dataframe(dataframe = val_set,\n    x_col = 'image', #name of the column containing the image in the validation set\n    y_col ='label', #name of column containing the target in the validation set set\n    target_size =(224, 224),\n    color_mode ='rgb',\n    class_mode ='categorical',\n    batch_size = 32,\n    shuffle = False #set to false so as not to shuffle the given data\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:54:04.862615Z","iopub.execute_input":"2022-07-15T07:54:04.863026Z","iopub.status.idle":"2022-07-15T07:54:09.530710Z","shell.execute_reply.started":"2022-07-15T07:54:04.862982Z","shell.execute_reply":"2022-07-15T07:54:09.529668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building Sequential CNN model ","metadata":{}},{"cell_type":"code","source":"#define the input shape\ninput_shape = (224, 224, 3)\n\n# define sequential model\nmodel = tf.keras.models.Sequential()\n# define conv-pool layers - set 1\nmodel.add(tf.keras.layers.Conv2D(filters = 32, kernel_size=(3, 3), strides=(1, 1), \n                                activation='relu', padding='valid', input_shape = input_shape))\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n\n\n# add flatten layer\nmodel.add(tf.keras.layers.Flatten())\n\n# add dense layers with some dropout\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(rate = 0.3))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\n\n# add output layer\nmodel.add(tf.keras.layers.Dense(9, activation='softmax')) #use softmax as activation in the output layer\n#as it is multiclass. Sigmoid activation is used for binary and 'relu' shouldnt be use for output layer\n\n\n# view model layers\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:54:09.532218Z","iopub.execute_input":"2022-07-15T07:54:09.532560Z","iopub.status.idle":"2022-07-15T07:54:11.953161Z","shell.execute_reply.started":"2022-07-15T07:54:09.532522Z","shell.execute_reply":"2022-07-15T07:54:11.952294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling Model\nmodel.compile(optimizer='adam', # optimize the model with adam optimizer\n              loss=\"categorical_crossentropy\", \n              metrics=['accuracy']) #to get accuracy of the model in each run\n","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:54:16.382557Z","iopub.execute_input":"2022-07-15T07:54:16.382878Z","iopub.status.idle":"2022-07-15T07:54:16.399262Z","shell.execute_reply.started":"2022-07-15T07:54:16.382847Z","shell.execute_reply":"2022-07-15T07:54:16.397912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train, #fit the model on the training set\n                    validation_data = val, #add the validation set to evaluate the performance in each run\n                    epochs = 15, \n                    verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-07-15T07:54:18.762166Z","iopub.execute_input":"2022-07-15T07:54:18.762490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy'] # get history report of the model\n\nval_acc = history.history['val_accuracy'] # get history of the validation set\n\nloss = history.history['loss'] #get the history of the lossses recorded on the train set\nval_loss = history.history['val_loss'] #get the history of the lossses recorded on the validation set\n\nplt.figure(figsize=(8, 8)) # set figure size for the plot generated\nplt.subplot(2, 1, 1) # a sup plot with 2 rows and 1 column\n\nplt.plot(acc, label='Training Accuracy') #plot accuracy curve for each train run\nplt.plot(val_acc, label='Validation Accuracy') #plot accuracy curve for each validation run\n\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy') #label name for y axis\nplt.ylim([min(plt.ylim()),1]) #set limit for y axis\nplt.title('Training and Validation Accuracy') #set title for the plot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 8)) # set figure size for the plot generated\nplt.subplot(2, 1, 1) # a sup plot with 2 rows and 1 column\n\nplt.plot(loss, label='Training Loss') #plot loss curve for each train run\nplt.plot(val_loss, label='Validation Loss') #plot loss curve for each validation run\n\nplt.legend(loc='lower right')\nplt.ylabel('Loss') #label name for y axis\nplt.ylim([min(plt.ylim()),1]) #set limit for y axis\nplt.title('Training and Validation Loss') #set title for the plot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the label of the test_images\npred = model.predict(test)\npred = np.argmax(pred,axis = 1) # pick the class with highest probability\n# sequential model predicts by given probability for each of the classes\n#np.argmax is called on the prediction to choose the class with the highest probability\n\n# Map the label\nlabels = (train.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred2 = [labels[k] for k in pred]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix # import metrics for evaluation\n\ny_test = test_set.label # set y_test to the expected output\n\nprint(classification_report(y_test, pred2)) # print the classification report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display 15 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\ncolor = \"blue\" if pred2[i] == test_set.label.iloc[i] else \"red\"\nfor i, ax ,in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_set.image.iloc[i]))\n    ax.set_title(f\"True: {test_set.label.iloc[i]}\\nPredicted: {pred2[i]}\",color=color)\n    \nplt.subplots_adjust(hspace = 0.3)\nplt.suptitle(\"Model predictions (blue: correct, red: incorrect)\",y=0.98)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}